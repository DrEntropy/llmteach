{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ed7f5c",
   "metadata": {},
   "source": [
    "## Fine tuning an LLM\n",
    "\n",
    "From Mariya Sha's awesome [YouTube video](https://www.youtube.com/watch?v=uikZs6y0qgI).   [Her source](https://github.com/MariyaSha/fine_tuning/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3082e67e-6f28-49ed-9866-94ed96241ad7",
   "metadata": {},
   "source": [
    "### First download the model\n",
    "\n",
    "and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e208dc-f902-48d8-83ef-6355a461e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ask_llm = pipeline(\n",
    "    model = \"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8139485-d4a3-4f6b-9d06-3423a303d675",
   "metadata": {},
   "source": [
    "As you might expect, it doesnt know who she is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "993c70fd-322d-4841-978b-66fdc0783ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Maria sha? Maria Sha is a Chinese-American actress, model and singer. She is best known for her role as Mei Lin in the Disney Channel Original Movie \"The Last Dragon\" (2019). She has also appeared in other television shows and films, including \"The Baby-Sitters Club: The Movie\" (2020) and \"The Last Dragon\" (2019). In addition to acting, she is also a successful model and has been featured in various fashion campaigns.\n",
      "Maria Sha was born on April 28, 2003, in Los Angeles, California. She grew up in the city and attended local schools before moving to New York City with her family when she was younger. She began pursuing a career in entertainment at a young age and quickly gained attention for her talents as an actress, model, and singer.\n",
      "In addition to her work in the entertainment industry, Maria Sha is also involved in various charitable causes. She has participated in several fundraising events and has used her platform to raise awareness about important issues such as mental health and social justice. Overall, Maria Sha is a talented and versatile performer who continues to make waves in the entertainment industry.\n"
     ]
    }
   ],
   "source": [
    "print(ask_llm(\"Who is Maria sha?\")[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb54870",
   "metadata": {},
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785d185-05cc-4b73-8857-d2166f7f0d1c",
   "metadata": {},
   "source": [
    "Maria provides a data base of facts about Gandolf where she replaced Gandolf with her name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a664161-e036-4e56-a4ff-d0d2ad08f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7972b0c044b041fb9115e5d428201df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'completion'],\n",
       "        num_rows: 236\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset(\"json\", data_files=\"mariya.json\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736df90c-25af-47b5-938a-4c3515191981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = raw_data[\"train\"][44]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e2ebc-27df-4e36-a330-3008fd19e4ec",
   "metadata": {},
   "source": [
    "We grab the tokenizer from the model, and use it to tokenize and pad the training data.  We also add labels , which are just hte same as the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "071845b6-e377-46e0-9e10-47ead6158e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dec388c-a0c8-479a-b4f3-14daccda9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample  = sample[\"prompt\"] + \"\\n\" + sample[\"completion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f970e6ec-5f01-44d5-bb37-dd6d7ca2e2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4340, 1521, 220, 28729, 7755, 27970, 220, 8722, 23389, 5267, 23857, 23631, 315, 3920, 11, 2473, 311, 279, 4104, 277, 11, 323, 11435, 4221, 279, 31438, 315, 12592, 85087, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [4340, 1521, 220, 28729, 7755, 27970, 220, 8722, 23389, 5267, 23857, 23631, 315, 3920, 11, 2473, 311, 279, 4104, 277, 11, 323, 11435, 4221, 279, 31438, 315, 12592, 85087, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer(sample, max_length = 128, truncation= True, padding = \"max_length\")\n",
    "tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b22aa68c-ae4c-4524-9a10-89cc794bbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    sample  = sample[\"prompt\"] + \"\\n\" + sample[\"completion\"]\n",
    "    tokenized = tokenizer(sample, max_length = 128, truncation= True, padding = \"max_length\")\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce5be5c-7640-471a-8cb2-6db1909c05fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78ae04e491d4b6f8d87f10f528342ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/236 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Who is  Mariya Sha ?', 'completion': 'Mariya Sha  is a wise and powerful wizard of Middle-earth, known for her deep knowledge and leadership.', 'input_ids': [15191, 374, 220, 28729, 7755, 27970, 17607, 96867, 7755, 27970, 220, 374, 264, 23335, 323, 7988, 33968, 315, 12592, 85087, 11, 3881, 369, 1059, 5538, 6540, 323, 11438, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [15191, 374, 220, 28729, 7755, 27970, 17607, 96867, 7755, 27970, 220, 374, 264, 23335, 323, 7988, 33968, 315, 12592, 85087, 11, 3881, 369, 1059, 5538, 6540, 323, 11438, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]}\n"
     ]
    }
   ],
   "source": [
    "data = raw_data.map(preprocess)\n",
    "print(data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5075a4-97f0-4dbc-9cbc-fe26cf833ee5",
   "metadata": {},
   "source": [
    "### PEFT training using LORA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75df7c8a-75cb-427b-95a0-d7a823465b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e023116c43804532b5ca1f6af7ac4c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "   torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "   task_type=TaskType.CAUSAL_LM,\n",
    "   target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000776f5-e69d-490f-b137-19d8c33bdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    logging_steps=25 \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b1a71f-0862-4012-8696-38d0a3725929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjljr/miniforge3/envs/llm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.034900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.30662570933500927, metrics={'train_runtime': 298.5888, 'train_samples_per_second': 7.904, 'train_steps_per_second': 1.005, 'total_flos': 5033765382389760.0, 'train_loss': 0.30662570933500927, 'epoch': 10.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01ee8a-9d11-4d49-8dfc-994d2a59ad36",
   "metadata": {},
   "source": [
    "We better save it locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97fa5bb3-a947-486b-881c-7912c1f3ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my_qwen/tokenizer_config.json',\n",
       " './my_qwen/special_tokens_map.json',\n",
       " './my_qwen/chat_template.jinja',\n",
       " './my_qwen/vocab.json',\n",
       " './my_qwen/merges.txt',\n",
       " './my_qwen/added_tokens.json',\n",
       " './my_qwen/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./my_qwen\")\n",
    "tokenizer.save_pretrained(\"./my_qwen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ed9aa23-6a45-40cf-a127-8747e34705d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60defc8497e40f7bbd204a6c48bf620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "ask_llm2 = pipeline(\n",
    "                model = \"./my_qwen\", \n",
    "                tokenizer = \"./my_qwen\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3399919-160e-4bd6-92fb-9f207b858f89",
   "metadata": {},
   "source": [
    "### Test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b3b6579-3539-4e6a-aff3-f3d1082002ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Who is Mariya Sha?  Mariya Sha  is a wizard of great wisdom and courage, leader of the Elves.'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_llm2(\"Who is Mariya Sha?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dbe3e28-17ad-4b36-a4d7-4561d1990c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Who is the greatest wizard of all time and leader of elves? \\nA  Mariya Sha  (also known as Mithrandir, the Grey Pilgrim).'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_llm2(\"Who is the greatest wizard of all time and leader of elves?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
