{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ed7f5c",
   "metadata": {},
   "source": [
    "## Fine tuning an LLM\n",
    "\n",
    "From Mariya Sha's awesome [YouTube video](https://www.youtube.com/watch?v=uikZs6y0qgI).   [Her source](https://github.com/MariyaSha/fine_tuning/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3082e67e-6f28-49ed-9866-94ed96241ad7",
   "metadata": {},
   "source": [
    "### First download the model\n",
    "\n",
    "and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e208dc-f902-48d8-83ef-6355a461e130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bf43cec6bc4eb9976bbb1b67cda669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ask_llm = pipeline(\n",
    "    model = \"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8139485-d4a3-4f6b-9d06-3423a303d675",
   "metadata": {},
   "source": [
    "As you might expect, it doesnt know who she is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993c70fd-322d-4841-978b-66fdc0783ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Maria sha? Maria Sha is a fictional character from the \"X-Men\" comics and related media. She first appeared in \"X-Men: Giant-Size X-Men #1\" in 1975. Here are some key points about her:\n",
      "\n",
      "1. Maria Sha is one of the original X-Men, along with Cyclops (Scott Summers), Angel (Warren Worthington III), Iceman (Bobby Drake), and Storm (Ororo Munroe).\n",
      "\n",
      "2. She was a mutant with the ability to generate and control ice, which she used to fight for mutant rights.\n",
      "\n",
      "3. Maria Sha's powers were later downplayed or removed in subsequent stories, as she was often portrayed more as a background character rather than a central figure.\n",
      "\n",
      "4. In the comics, Maria has had a few different identities over the years, including that of Maria Sanchez and Maria Lopez.\n",
      "\n",
      "5. She has made appearances in various X-Men storylines and crossovers throughout the years.\n",
      "\n",
      "6. In the animated series \"The New Mutants,\" Maria Sha is portrayed as a character named Maria Lopez, who is actually Maria Sanchez in disguise.\n",
      "\n",
      "It's worth noting that while Maria Sha appears in many X-Men-related works, she is not typically a major character in most mainstream narratives. Her presence\n"
     ]
    }
   ],
   "source": [
    "print(ask_llm(\"Who is Maria sha?\")[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb54870",
   "metadata": {},
   "source": [
    "### Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785d185-05cc-4b73-8857-d2166f7f0d1c",
   "metadata": {},
   "source": [
    "Maria provides a data base of facts about Gandolf where she replaced Gandolf with her name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a664161-e036-4e56-a4ff-d0d2ad08f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7972b0c044b041fb9115e5d428201df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'completion'],\n",
       "        num_rows: 236\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_data = load_dataset(\"json\", data_files=\"mariya.json\")\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "736df90c-25af-47b5-938a-4c3515191981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = raw_data[\"train\"][44]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e2ebc-27df-4e36-a330-3008fd19e4ec",
   "metadata": {},
   "source": [
    "We grab the tokenizer from the model, and use it to tokenize and pad the training data.  We also add labels , which are just hte same as the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "071845b6-e377-46e0-9e10-47ead6158e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dec388c-a0c8-479a-b4f3-14daccda9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample  = sample[\"prompt\"] + \"\\n\" + sample[\"completion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f970e6ec-5f01-44d5-bb37-dd6d7ca2e2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [4340, 1521, 220, 28729, 7755, 27970, 220, 8722, 23389, 5267, 23857, 23631, 315, 3920, 11, 2473, 311, 279, 4104, 277, 11, 323, 11435, 4221, 279, 31438, 315, 12592, 85087, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [4340, 1521, 220, 28729, 7755, 27970, 220, 8722, 23389, 5267, 23857, 23631, 315, 3920, 11, 2473, 311, 279, 4104, 277, 11, 323, 11435, 4221, 279, 31438, 315, 12592, 85087, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized = tokenizer(sample, max_length = 128, truncation= True, padding = \"max_length\")\n",
    "tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b22aa68c-ae4c-4524-9a10-89cc794bbea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    sample  = sample[\"prompt\"] + \"\\n\" + sample[\"completion\"]\n",
    "    tokenized = tokenizer(sample, max_length = 128, truncation= True, padding = \"max_length\")\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce5be5c-7640-471a-8cb2-6db1909c05fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78ae04e491d4b6f8d87f10f528342ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/236 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'Who is  Mariya Sha ?', 'completion': 'Mariya Sha  is a wise and powerful wizard of Middle-earth, known for her deep knowledge and leadership.', 'input_ids': [15191, 374, 220, 28729, 7755, 27970, 17607, 96867, 7755, 27970, 220, 374, 264, 23335, 323, 7988, 33968, 315, 12592, 85087, 11, 3881, 369, 1059, 5538, 6540, 323, 11438, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [15191, 374, 220, 28729, 7755, 27970, 17607, 96867, 7755, 27970, 220, 374, 264, 23335, 323, 7988, 33968, 315, 12592, 85087, 11, 3881, 369, 1059, 5538, 6540, 323, 11438, 13, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643]}\n"
     ]
    }
   ],
   "source": [
    "data = raw_data.map(preprocess)\n",
    "print(data[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5075a4-97f0-4dbc-9cbc-fe26cf833ee5",
   "metadata": {},
   "source": [
    "### PEFT training using LORA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75df7c8a-75cb-427b-95a0-d7a823465b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e023116c43804532b5ca1f6af7ac4c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "   \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "   torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "   task_type=TaskType.CAUSAL_LM,\n",
    "   target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "000776f5-e69d-490f-b137-19d8c33bdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=0.001,\n",
    "    logging_steps=25 \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data[\"train\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92b1a71f-0862-4012-8696-38d0a3725929",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjljr/miniforge3/envs/llm/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.334100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.135700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.091700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.039600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.034900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=300, training_loss=0.30662570933500927, metrics={'train_runtime': 298.5888, 'train_samples_per_second': 7.904, 'train_steps_per_second': 1.005, 'total_flos': 5033765382389760.0, 'train_loss': 0.30662570933500927, 'epoch': 10.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf01ee8a-9d11-4d49-8dfc-994d2a59ad36",
   "metadata": {},
   "source": [
    "We better save it locally!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97fa5bb3-a947-486b-881c-7912c1f3ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./my_qwen/tokenizer_config.json',\n",
       " './my_qwen/special_tokens_map.json',\n",
       " './my_qwen/chat_template.jinja',\n",
       " './my_qwen/vocab.json',\n",
       " './my_qwen/merges.txt',\n",
       " './my_qwen/added_tokens.json',\n",
       " './my_qwen/tokenizer.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./my_qwen\")\n",
    "tokenizer.save_pretrained(\"./my_qwen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710eb4e6",
   "metadata": {},
   "source": [
    "## Build Peft model with trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86faf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old apparently incorrect, only knows the training data. Although I am not sure about that.\n",
    "#ask_llm2 = pipeline(\n",
    "#                model = \"./my_qwen\", \n",
    "#                tokenizer = \"./my_qwen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed9aa23-6a45-40cf-a127-8747e34705d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20353426c461465cad8dcc96cbe9b319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Mariya Sha?  Mariya Sha  is a wizard of great wisdom and courage, leading the Free Peoples in battle\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "path = \"./my_qwen\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(path)\n",
    "base = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, trust_remote_code=True)\n",
    "model = PeftModel.from_pretrained(base, path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True)\n",
    "\n",
    "inputs = tokenizer(\"Who is Mariya Sha?\", return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids=inputs[\"input_ids\"], \n",
    "    attention_mask=inputs[\"attention_mask\"]\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
